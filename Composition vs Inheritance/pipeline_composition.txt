ğŸ“Œ Topic: Composition vs Inheritance

Goal for today (2.5 hrs):

Understand when to use inheritance

Understand why composition is often preferred

Design an ML-style pipeline using composition

Produce pipeline skeleton code (your planned output)

1ï¸âƒ£ First, the REAL Question Interviewers Ask

They are not asking:

â€œWhat is inheritance?â€

They are asking:

â€œHow do you design systems that donâ€™t break when requirements change?â€

Thatâ€™s why composition vs inheritance matters.

2ï¸âƒ£ Inheritance (IS-A relationship)
ğŸ”¹ Concept

Inheritance means:

One class IS A type of another class

class Animal:
    def speak(self):
        pass

class Dog(Animal):
    def speak(self):
        return "Bark"


âœ” Dog is an Animal

ğŸ”¹ Advantages

Code reuse

Polymorphism

Clear hierarchy (when it truly exists)

ğŸ”¹ Problems with Inheritance âš ï¸
class Bird:
    def fly(self):
        return "Flying"

class Ostrich(Bird):
    pass


âŒ Ostrich cannot fly, but inheritance forces it.

ğŸ“Œ This is called fragile base class problem.

3ï¸âƒ£ Composition (HAS-A relationship) â­â­â­
ğŸ”¹ Concept

Composition means:

A class HAS A component

Instead of inheriting behavior, you inject it.

Example
class Engine:
    def start(self):
        return "Engine started"

class Car:
    def __init__(self, engine):
        self.engine = engine

    def drive(self):
        return self.engine.start()


âœ” Car has an Engine
âœ” Engine can be swapped later

4ï¸âƒ£ Side-by-Side Comparison (INTERVIEW GOLD)
Aspect	Inheritance	Composition
Relationship	IS-A	HAS-A
Flexibility	âŒ Low	âœ… High
Coupling	Tight	Loose
Easy to change	âŒ Risky	âœ… Safe
Preferred in real systems	âŒ Rare	âœ… Very common

ğŸ§  Rule of Thumb

Favor composition over inheritance

(You can literally say this in interviews.)

5ï¸âƒ£ Why ML / Data Pipelines Use Composition

Think about a pipeline:

Read data

Clean data

Transform data

Validate data

Export data

âŒ Inheritance makes this rigid
âœ… Composition makes this modular

6ï¸âƒ£ âŒ Bad Design (Inheritance-based Pipeline)
class Pipeline:
    def process(self, data):
        pass

class CleanPipeline(Pipeline):
    def process(self, data):
        return [x for x in data if x is not None]

class NormalizePipeline(CleanPipeline):
    def process(self, data):
        data = super().process(data)
        return [x / max(data) for x in data]


âš ï¸ Problems:

Hard-coded order

Hard to reuse steps

Inflexible

7ï¸âƒ£ âœ… Correct Design (Composition-based Pipeline)
ğŸ”¹ Step Components
class Cleaner:
    def run(self, data):
        return [x for x in data if x is not None]


class Normalizer:
    def run(self, data):
        max_val = max(data)
        return [x / max_val for x in data]

ğŸ”¹ Pipeline Using Composition
class Pipeline:
    def __init__(self, steps):
        self.steps = steps

    def run(self, data):
        for step in self.steps:
            data = step.run(data)
        return data

ğŸ”¹ Usage
pipeline = Pipeline([
    Cleaner(),
    Normalizer()
])

result = pipeline.run([10, None, 20, 30])
print(result)


âœ… Modular
âœ… Extensible
âœ… Interview-ready

8ï¸âƒ£ Extend Pipeline Easily (Why Composition Wins)
class Scaler:
    def run(self, data):
        return [x * 100 for x in data]


Just plug it in:

pipeline = Pipeline([
    Cleaner(),
    Normalizer(),
    Scaler()
])


ğŸš€ No existing code changes required.

9ï¸âƒ£ Key Design Principle (Say This Confidently)

Inheritance models identity
Composition models behavior


ğŸ§  WHY we are doing this (context)

This single exercise covers multiple interview signals:

Design thinking (composition)

Clean OOP

Extensibility

Debugging & reasoning

Real-world relevance (ML / data pipelines)

If you master this one topic, youâ€™ll outperform many candidates.

1ï¸âƒ£ Why COMPOSITION is better (in simple words)

Use this explanation as-is in interviews:

Composition is better because it keeps classes loosely coupled.
Each component does one job and can be added, removed, or replaced without modifying existing code.
This makes systems easier to extend, test, and maintain as requirements change.

One-liner (gold)

Inheritance models identity, composition models behavior.

2ï¸âƒ£ pipeline_composition_example.py âœ…

ğŸ‘‰ Copyâ€“paste and save exactly with this name

"""
pipeline_composition_example.py
--------------------------------
Topic: Composition over Inheritance
Use case: ML / Data Processing Pipeline
"""

# ============================================================
# PIPELINE STEPS
# ============================================================

class Cleaner:
    def run(self, data):
        """Remove None and invalid values"""
        return [x for x in data if isinstance(x, (int, float))]


class Validator:
    def run(self, data):
        """Ensure data is not empty"""
        if not data:
            raise ValueError("Data validation failed: empty dataset")
        return data


class Normalizer:
    def run(self, data):
        """Normalize values between 0 and 1"""
        max_val = max(data)
        return [x / max_val for x in data]


class Logger:
    def run(self, data):
        """Log data length (side-effect allowed here)"""
        print(f"[LOG] Records count: {len(data)}")
        return data


# ============================================================
# PIPELINE (COMPOSITION)
# ============================================================

class Pipeline:
    def __init__(self, steps):
        self.steps = steps

    def run(self, data):
        for step in self.steps:
            data = step.run(data)
        return data


# ============================================================
# USAGE
# ============================================================

if __name__ == "__main__":
    raw_data = [10, None, 20, "x", 30]

    pipeline = Pipeline([
        Cleaner(),
        Validator(),
        Logger(),
        Normalizer()
    ])

    result = pipeline.run(raw_data)
    print("Final Output:", result)

3ï¸âƒ£ Practice Tasks â€” DONE STEP BY STEP
âœ… Add 2 more steps

âœ” Validator
âœ” Logger

Already implemented above.

âœ… Change pipeline order (NO code changes)
pipeline = Pipeline([
    Cleaner(),
    Logger(),
    Validator(),
    Normalizer()
])


âœ” Works
âœ” No pipeline modification
âœ” Composition advantage proven

âœ… Swap steps without touching pipeline class

Remove normalization:

pipeline = Pipeline([
    Cleaner(),
    Validator(),
    Logger()
])


âœ” Still works
âœ” Zero refactor
âœ” Interview gold

4ï¸âƒ£ Predict Output â€” Composition vs Inheritance (INTERVIEW TRAPS)
ğŸ”¥ Question 1: Step Order
pipeline = Pipeline([
    Logger(),
    Cleaner()
])

pipeline.run([1, None, 2])

âœ… Output
[LOG] Records count: 3


ğŸ§  Logger runs before cleaning

ğŸ”¥ Question 2: Validator Failure
pipeline = Pipeline([
    Cleaner(),
    Validator()
])

pipeline.run([None, None])

âœ… Output
ValueError: Data validation failed: empty dataset


ğŸ§  Validator correctly blocks pipeline

ğŸ”¥ Question 3: Why inheritance fails here
class CleanPipeline:
    def run(self, data):
        return [x for x in data if x]

class NormalizePipeline(CleanPipeline):
    def run(self, data):
        data = super().run(data)
        return [x / max(data) for x in data]


â“ What if we want logging between clean & normalize?

âŒ You must rewrite classes
âŒ Tight coupling
âŒ Bad design

ğŸ”¥ Question 4: Component Reuse
logger = Logger()

pipeline1 = Pipeline([Cleaner(), logger])
pipeline2 = Pipeline([Validator(), logger])


âœ… Logger reused
âŒ Impossible with inheritance

5ï¸âƒ£ Mini Interview Project (FINAL FORM)
ğŸ¯ Project Name

Config-Driven Data Processing Pipeline

ğŸ§© Problem Statement (Say this)

Design a flexible data pipeline where processing steps can be added, removed, or reordered without modifying the core pipeline logic.

ğŸ—ï¸ Design Choices
Aspect	Choice
Design Pattern	Composition
Pipeline Control	Step injection
Extensibility	High
Testing	Each step independently testable
ğŸ§  Why Interviewers Like This

âœ” Shows SOLID principles
âœ” Shows real-world thinking
âœ” Matches ML / ETL systems
âœ” Easy to explain & extend

â­ How to Extend (Bonus)

Add config-driven steps:

STEP_REGISTRY = {
    "clean": Cleaner,
    "validate": Validator,
    "log": Logger,
    "normalize": Normalizer
}

steps = ["clean", "validate", "normalize"]
pipeline = Pipeline([STEP_REGISTRY[s]() for s in steps])


ğŸ’¥ This is senior-level thinking.